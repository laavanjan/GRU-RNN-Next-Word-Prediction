# ğŸ“– Next Word Prediction with GRU & LSTM ğŸš€

## Overview

This application uses Gated Recurrent Unit (GRU) and Long Short-Term Memory (LSTM) models to predict the next word in a sequence from Shakespeare's Hamlet. Built with TensorFlow, Keras, and Streamlit, it leverages deep learning to generate context-aware predictions based on previous words. The interactive Streamlit UI allows users to input text and receive predictions, showcasing the power of LSTM and GRU models in natural language processing.



## ğŸ”— Links

- ğŸŒ **Live Demo:** [LLVE Demo](https://gru-rnn-next-word-prediction-z3yqw82qfxbf3wqeeruhhg.streamlit.app/)
- ğŸ“‚ **GitHub Repo:** [GRU-RNN-Next-Word-Prediction](https://github.com/laavanjan/GRU-RNN-Next-Word-Prediction)

## âœ¨ Features

- ğŸ”¥ Implements both **GRU** and **LSTM** for next-word prediction.
- ğŸ“œ Uses **tokenization** and **sequence padding** for input processing.
- ğŸ–¥ï¸ Provides an interactive **Streamlit** web app for predictions.
- â³ Trained with **early stopping** to optimize performance.

## ğŸ› ï¸ Tech Stack

- ğŸ **Python 3.11**
- ğŸ¤– **TensorFlow 2.28/Keras** for deep learning
- ğŸŒ **Streamlit** for UI
- ğŸ—„ï¸ **Pickle** for tokenizer storage
- ğŸ”¢ **NumPy,Pandas** for numerical computations



## ğŸ—ï¸ Installation

Clone this repository:

```bash
 git clone https://github.com/laavanjan/GRU-RNN-Next-Word-Prediction
 cd GRU-RNN-Next-Word-Prediction
```

Create and activate a **Conda** virtual environment:

```bash
 conda create --name nextword_env python=3.11
 conda activate nextword_env
```

Install dependencies:

```bash
 pip install -r requirements.txt
```

## ğŸš€ How to Use

1. Run the Streamlit app:
   ```bash
   streamlit run app.py
   ```
2. Enter a sequence of words in the text box.
3. Click the "Predict Next Word" button to get the model's prediction.

## ğŸ“‚ File Structure

```
ğŸ“‚ GRU-RNN-Next-Word-Prediction
â”œâ”€â”€ app.py  # Streamlit app for predictions
â”œâ”€â”€ next_word_lstm.h5  # Trained LSTM model
â”œâ”€â”€ tokenizer.pickle  # Saved tokenizer
â”œâ”€â”€ requirements.txt  # Dependencies
â””â”€â”€ experiments.ipynb  # Jupyter notebook for training
```

## ğŸ”® Future Improvements

- ğŸ”„ Add support for **bi-directional LSTMs**
- ğŸ“ˆ Train with **larger datasets** for better accuracy
- ğŸŒ Deploy the model as a **REST API**
- ğŸ“Š Include **visualizations and model performance metrics**

## ğŸ–¼ï¸ Images



## ğŸ“œ License

This project is open-source under the **GPL License**.

